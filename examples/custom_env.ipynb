{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = %pwd\n",
    "\n",
    "import os, sys\n",
    "sys.path.insert(0, os.path.join(pwd, \"../\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "-------\n",
    "\n",
    "自作環境を用意するには 'srl.base.env.EnvBase' を継承して作ります。  \n",
    "ただ、作りたい環境によってはいらない情報もあるので、  \n",
    "'srl.base.env.genre'に各環境に合わせたインタフェースも用意しています。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは一人プレイでアクションと状態が共に離散値を取る環境を作成していきます。  \n",
    "'srl.base.env.genre.singleplay.SingleActionDiscrete' を継承してクラスを作っていきます。\n",
    "\n",
    "以下のプロパティと関数が必要となります。\n",
    "\n",
    "``` python\n",
    "from typing import Any, List, Tuple, cast\n",
    "\n",
    "import gym.spaces\n",
    "from srl.base.env.genre.singleplay import SingleActionDiscrete\n",
    "from srl.base.define import EnvObservationType\n",
    "\n",
    "class MyEnv(SingleActionDiscrete):\n",
    "\n",
    "    # 取りうるアクションの数を返す\n",
    "    @property\n",
    "    def action_num(self) -> int:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    # 状態の取りうる値(gym.spacesで指定、将来的に変わるかも？ TODO)\n",
    "    @property\n",
    "    def observation_space(self) -> gym.spaces.Space:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    # 環境の種類を指定\n",
    "    @property\n",
    "    def observation_type(self) -> EnvObservationType:\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    # 1エピソードの最大ターン数\n",
    "    @property\n",
    "    def max_episode_steps(self) -> int:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    # エピソードの最初に呼ばれる関数\n",
    "    # 初期状態を返す\n",
    "    def reset_single(self) -> Any:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    # 1stepの関数\n",
    "    # アクションを受け取り、1step進めて、[状態,報酬,終わりか,情報]を返す\n",
    "    def step_single(self, action: int) -> Tuple[Any, float, bool, dict]:\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    # backup/restoreで環境の状態を保存・復元できるように関数を作る\n",
    "    def backup(self) -> Any:\n",
    "        raise NotImplementedError()\n",
    "    def restore(self, data: Any) -> None:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    # 可視化用の関数(option)\n",
    "    def render_terminal(self, **kwargs) -> None:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def render_gui(self, **kwargs) -> None:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def render_rgb_array(self, **kwargs) -> np.ndarray:\n",
    "        raise NotImplementedError()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際に作ってみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, List, Tuple, cast\n",
    "\n",
    "import gym.spaces\n",
    "import numpy as np\n",
    "from srl.base.env.genre.singleplay import SingleActionDiscrete\n",
    "from srl.base.define import EnvObservationType\n",
    "\n",
    "\n",
    "class Action(enum.Enum):\n",
    "    LEFT = 0\n",
    "    DOWN = 1\n",
    "    RIGHT = 2\n",
    "    UP = 3\n",
    "\n",
    "@dataclass\n",
    "class MyEnv(SingleActionDiscrete):\n",
    "    \n",
    "    move_reward: float = -0.04\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.base_field = [\n",
    "            [0, 0, 0, 1],\n",
    "            [0, 9, 0, -1],\n",
    "            [0, 0, 0, 0],\n",
    "        ]\n",
    "        self.H = 3\n",
    "        self.W = 4\n",
    "    \n",
    "    @property\n",
    "    def action_num(self) -> int:\n",
    "        return len(Action)\n",
    "\n",
    "    @property\n",
    "    def observation_space(self) -> gym.spaces.Space:\n",
    "        return gym.spaces.Box(\n",
    "            low=0,\n",
    "            high=np.asarray([self.W, self.H]),\n",
    "            shape=(2,),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def observation_type(self) -> EnvObservationType:\n",
    "        return EnvObservationType.DISCRETE\n",
    "    \n",
    "    @property\n",
    "    def max_episode_steps(self) -> int:\n",
    "        return 100\n",
    "\n",
    "    def reset_single(self) -> Any:\n",
    "        self.player_pos = [0, 2]\n",
    "        return tuple(self.player_pos)\n",
    "\n",
    "    def step_single(self, action_: int) -> Tuple[Any, float, bool, dict]:\n",
    "        action = Action(action_)\n",
    "\n",
    "        next_player_pos = self.player_pos[:]\n",
    "\n",
    "        if action == Action.UP:\n",
    "            next_player_pos[1] -= 1\n",
    "        elif action == Action.DOWN:\n",
    "            next_player_pos[1] += 1\n",
    "        elif action == Action.LEFT:\n",
    "            next_player_pos[0] -= 1\n",
    "        elif action == Action.RIGHT:\n",
    "            next_player_pos[0] += 1\n",
    "        else:\n",
    "            raise ValueError()\n",
    "\n",
    "        is_move = True\n",
    "        if not (0 <= next_player_pos[0] < self.W):\n",
    "            is_move = False\n",
    "        elif not (0 <= next_player_pos[1] < self.H):\n",
    "            is_move = False\n",
    "        elif self.base_field[next_player_pos[1]][next_player_pos[0]] == 9:\n",
    "            is_move = False\n",
    "\n",
    "        if is_move:\n",
    "            self.player_pos = next_player_pos\n",
    "\n",
    "        reward = self.move_reward\n",
    "        done = False\n",
    "\n",
    "        attribute = self.base_field[self.player_pos[1]][self.player_pos[0]]\n",
    "        if attribute == 1:\n",
    "            reward = 1\n",
    "            done = True\n",
    "        elif attribute == -1:\n",
    "            reward = -1\n",
    "            done = True\n",
    "\n",
    "        return tuple(self.player_pos), reward, done, {}\n",
    "    \n",
    "    def backup(self) -> Any:\n",
    "        return self.player_pos[:]\n",
    "\n",
    "    def restore(self, data: Any) -> None:\n",
    "        self.player_pos = data\n",
    "\n",
    "    def render_terminal(self):\n",
    "        for y in range(self.H):\n",
    "            s = \"\"\n",
    "            for x in range(self.W):\n",
    "                n = self.base_field[y][x]\n",
    "                if self.player_pos[0] == x and self.player_pos[1] == y:  # player\n",
    "                    s += \"P\"\n",
    "                elif n == 0:  # 道\n",
    "                    s += \".\"\n",
    "                elif n == 1:  # goal\n",
    "                    s += \"G\"\n",
    "                elif n == -1:  # 穴\n",
    "                    s += \"X\"\n",
    "                else:\n",
    "                    s += str(n)\n",
    "            print(s)\n",
    "        print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成出来たら登録します。  \n",
    "引数は以下です。  \n",
    "\n",
    "``` python\n",
    "id: ユニークな名前  \n",
    "entry_point: __name__ + \":\" + クラス名  \n",
    "kwargs: クラス生成時の引数\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srl.base.env import registration\n",
    "\n",
    "registration.register(\n",
    "    id=\"MyEnv\",\n",
    "    entry_point=__name__ + \":MyEnv\",\n",
    "    kwargs={\n",
    "        \"move_reward\": -0.04,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のように実行できます。  \n",
    "'SinglePlayerWrapper' を通すとシングルプレイ用のインタフェースで実行できます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...G\n",
      ".9.X\n",
      "P...\n",
      "\n",
      "step 1, action 0, reward -0.04, done False\n",
      "...G\n",
      ".9.X\n",
      "P...\n",
      "\n",
      "step 2, action 2, reward -0.04, done False\n",
      "...G\n",
      ".9.X\n",
      ".P..\n",
      "\n",
      "step 3, action 2, reward -0.04, done False\n",
      "...G\n",
      ".9.X\n",
      "..P.\n",
      "\n",
      "step 4, action 3, reward -0.04, done False\n",
      "...G\n",
      ".9PX\n",
      "....\n",
      "\n",
      "step 5, action 1, reward -0.04, done False\n",
      "...G\n",
      ".9.X\n",
      "..P.\n",
      "\n",
      "step 6, action 3, reward -0.04, done False\n",
      "...G\n",
      ".9PX\n",
      "....\n",
      "\n",
      "step 7, action 1, reward -0.04, done False\n",
      "...G\n",
      ".9.X\n",
      "..P.\n",
      "\n",
      "step 8, action 0, reward -0.04, done False\n",
      "...G\n",
      ".9.X\n",
      ".P..\n",
      "\n",
      "step 9, action 1, reward -0.04, done False\n",
      "...G\n",
      ".9.X\n",
      ".P..\n",
      "\n",
      "step 10, action 1, reward -0.04, done False\n",
      "...G\n",
      ".9.X\n",
      ".P..\n",
      "\n",
      "step 11, action 3, reward -0.04, done False\n",
      "...G\n",
      ".9.X\n",
      ".P..\n",
      "\n",
      "step 12, action 1, reward -0.04, done False\n",
      "...G\n",
      ".9.X\n",
      ".P..\n",
      "\n",
      "step 13, action 2, reward -0.04, done False\n",
      "...G\n",
      ".9.X\n",
      "..P.\n",
      "\n",
      "step 14, action 1, reward -0.04, done False\n",
      "...G\n",
      ".9.X\n",
      "..P.\n",
      "\n",
      "step 15, action 2, reward -0.04, done False\n",
      "...G\n",
      ".9.X\n",
      "...P\n",
      "\n",
      "step 16, action 3, reward -1, done True\n",
      "...G\n",
      ".9.P\n",
      "....\n",
      "\n",
      "-1.6\n"
     ]
    }
   ],
   "source": [
    "import srl\n",
    "from srl.base.env.singleplay_wrapper import SinglePlayerWrapper\n",
    "\n",
    "env = srl.envs.make(\"MyEnv\")\n",
    "env = SinglePlayerWrapper(env)  # change single play interface\n",
    "\n",
    "env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "step = 0\n",
    "env.render()\n",
    "\n",
    "while not done:\n",
    "    action = env.sample()\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    step += 1\n",
    "    print(f\"step {step}, action {action}, reward {reward}, done {done}\")\n",
    "    env.render()\n",
    "\n",
    "print(total_reward)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runnerを使うと以下のように学習できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### env: MyEnv, max episodes: 10000, max steps: -1, timeout:  -1.00s\n",
      "20:42:41   0.00s   10000ep   55143tr   0.00s(remain), -1.960 0.760 0.840 reward, 5.5 step, 0.00s/ep, 0.0000s/tr,        0 mem|Q 10.999|td_error 0.005\n"
     ]
    }
   ],
   "source": [
    "import srl\n",
    "from srl.runner import sequence\n",
    "from srl.runner.callbacks import PrintProgress\n",
    "\n",
    "config = sequence.Config(\n",
    "    env_name=\"MyEnv\",\n",
    "    rl_config=srl.rl.ql.Config(),  # Q学習\n",
    ")\n",
    "\n",
    "# --- train\n",
    "config.set_play_config(max_episodes=10000, training=True, callbacks=[PrintProgress()])\n",
    "parameter, memory = sequence.train(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100エピソードの平均結果 0.8400000000000002\n"
     ]
    }
   ],
   "source": [
    "config.set_play_config(max_episodes=100)\n",
    "rewards, _, _ = sequence.play(config, parameter)\n",
    "print(\"100エピソードの平均結果\", np.mean(rewards))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 0\n",
      "...G\n",
      ".9.X\n",
      "P...\n",
      "\n",
      " 0: 0.42669\n",
      " 1: 0.42669\n",
      "*2: 0.51854\n",
      " 3: 0.51854\n",
      "### 1, done: False\n",
      "player 0, action 2, reward: -0.04\n",
      "...G\n",
      ".9.X\n",
      ".P..\n",
      "\n",
      "env_info  : {}\n",
      "work_info 0: {}\n",
      "train_info: None\n",
      " 0: 0.42669\n",
      " 1: 0.51854\n",
      "*2: 0.62060\n",
      " 3: 0.51854\n",
      "### 2, done: False\n",
      "player 0, action 2, reward: -0.04\n",
      "...G\n",
      ".9.X\n",
      "..P.\n",
      "\n",
      "env_info  : {}\n",
      "work_info 0: {}\n",
      "train_info: None\n",
      " 0: 0.51854\n",
      " 1: 0.62060\n",
      " 2: 0.51854\n",
      "*3: 0.73400\n",
      "### 3, done: False\n",
      "player 0, action 3, reward: -0.04\n",
      "...G\n",
      ".9PX\n",
      "....\n",
      "\n",
      "env_info  : {}\n",
      "work_info 0: {}\n",
      "train_info: None\n",
      " 0: 0.73400\n",
      " 1: 0.62060\n",
      " 2: -1.00000\n",
      "*3: 0.86000\n",
      "### 4, done: False\n",
      "player 0, action 3, reward: -0.04\n",
      "..PG\n",
      ".9.X\n",
      "....\n",
      "\n",
      "env_info  : {}\n",
      "work_info 0: {}\n",
      "train_info: None\n",
      " 0: 0.73400\n",
      " 1: 0.73400\n",
      "*2: 1.00000\n",
      " 3: 0.86000\n",
      "### 5, done: True\n",
      "player 0, action 2, reward: 1.0\n",
      "...P\n",
      ".9.X\n",
      "....\n",
      "\n",
      "env_info  : {}\n",
      "work_info 0: {}\n",
      "train_info: None\n"
     ]
    }
   ],
   "source": [
    "from srl.runner.callbacks import Rendering\n",
    "\n",
    "config.set_play_config(max_episodes=1, callbacks=[Rendering(step_stop=False)])\n",
    "_ = sequence.play(config, parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea4fe4d9f7a0ac0973d73e7eb814bdfb578c3b05679fd701fb5853be0632daec"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('biz310': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
